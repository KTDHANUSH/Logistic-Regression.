{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Logistic Regression***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_ZUh357SHugs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "Logistic Regression is a statistical model used for classification tasks (binary or multiclass). It predicts the probability of a class using the logistic (sigmoid) function.\n",
        "\n",
        "**Linear Regression** → predicts continuous values (e.g., house prices).\n",
        "\n",
        "**Logistic Regression** → predicts probabilities between 0 and 1, then classifies into categories.\n",
        "\n"
      ],
      "metadata": {
        "id": "mxNPsNIVHy7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: Explain the role of the Sigmoid function in Logistic Regression.**\n",
        "**Answer:**\n",
        "\n",
        "The Sigmoid function maps the model’s linear output (which can be any real number) into a probability between 0 and 1:\n",
        "\n",
        "σ\n",
        "(\n",
        "z\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "e\n",
        "−\n",
        "z\n",
        "σ(z)=\n",
        "1+e\n",
        "−z\n",
        "\n",
        "1\n",
        "​\n",
        "\n",
        "Ensures predictions are probabilities.\n",
        "\n",
        "Thresholding (e.g., ≥0.5 = Class 1, <0.5 = Class 0) helps classify outcomes."
      ],
      "metadata": {
        "id": "sI_e-dVLHy4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: What is Regularization in Logistic Regression and why is it needed?**\n",
        "**Answer:**\n",
        "Regularization adds a penalty to large coefficients in the model to reduce overfitting.\n",
        "\n",
        "L1 (Lasso): encourages sparsity (some coefficients = 0).\n",
        "\n",
        "L2 (Ridge): shrinks coefficients but keeps all features.\n",
        "It helps improve generalization to unseen data."
      ],
      "metadata": {
        "id": "UWW1BBcUHy2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: What are some common evaluation metrics for classification models, and why are they important?**\n",
        "**Answer:**\n",
        "\n",
        "**Accuracy** → % of correct predictions.\n",
        "\n",
        "**Precision **→ fraction of true positives among predicted positives.\n",
        "\n",
        "**Recall** (Sensitivity) → fraction of true positives among actual positives.\n",
        "\n",
        "**F1-score** → harmonic mean of precision & recall.\n",
        "\n",
        "**ROC-AUC** → measures discrimination ability.\n",
        "\n",
        "These are important because relying only on accuracy can be misleading, especially with imbalanced datasets."
      ],
      "metadata": {
        "id": "-sEJ9EcDHyzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZGzAz0_JV41",
        "outputId": "8629aa27-e1f2-4ec3-efb7-6c7265ac0ac3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9707602339181286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6: Write a Python program to train a Logistic Regression model using L2regularization (Ridge) and print the model coefficients and accuracy\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ2iDENLJsK7",
        "outputId": "c81c3bd6-06e4-4abc-e0e8-135bec2fd6bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [[ 2.37436834  0.16536488 -0.34074222  0.009497   -0.1759965  -0.367409\n",
            "  -0.77856024 -0.49205038 -0.25026609 -0.01511331 -0.10328272  1.14760081\n",
            "   0.25829795 -0.11373373 -0.02606671  0.06305927 -0.01242942 -0.057764\n",
            "  -0.04708287  0.0103125   1.34726796 -0.39195314 -0.01971088 -0.0271816\n",
            "  -0.33407715 -0.78851603 -1.69319834 -0.80679759 -0.87058696 -0.06330855]]\n",
            "Accuracy: 0.9707602339181286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Write a Python program to train a Logistic Regression model for multiclassclassification using multi_class='ovr' and print the classification report.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load multiclass dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za_kpDLqJ2BW",
        "outputId": "b752bf31-82fb-44ae-c2db-9ff17863cb12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       0.87      1.00      0.93        13\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.95      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to apply GridSearchCV to tune C and penaltyhyperparameters for Logistic Regression and print the best parameters and validationaccuracy.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # supports both L1 and L2\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=500), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Validation Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI6xzpVJJ8ju",
        "outputId": "dfae821e-ce27-4228-efdf-4c96d149fdf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Validation Accuracy: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to standardize the features before training LogisticRegression and compare the model's accuracy with and without scaling.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Without scaling\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy without scaling:\", accuracy_score(y_test, model.predict(X_test)))\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\"Accuracy with scaling:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-7BqZZFKG_d",
        "outputId": "5f28673e-c930-43b8-bd17-e71ad0817b1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0\n",
            "Accuracy with scaling: 0.28888888888888886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10**:** Imagine you are working at an e-commerce company that wants to**\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing\n",
        "classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case.\n",
        "**ANSWER**\n",
        "\n",
        "If only 5% of customers respond (highly imbalanced):\n",
        "\n",
        "Data Handling: Clean nulls, encode categorical features, scale numerical ones.\n",
        "\n",
        "Feature Scaling: Apply StandardScaler for better optimization.\n",
        "\n",
        "Balancing Classes: Use SMOTE (oversampling), undersampling, or class weights (class_weight='balanced').\n",
        "\n",
        "Hyperparameter Tuning: Use GridSearchCV to optimize C, penalty.\n",
        "\n",
        "Evaluation: Don’t rely on accuracy — instead, use Precision, Recall, F1-score, ROC-AUC to evaluate.\n",
        "\n",
        "Deployment: Threshold tuning (e.g., instead of 0.5, pick 0.3 if recall is more important)."
      ],
      "metadata": {
        "id": "XNsxXTtJKSnu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rnruL_zKNzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U-4Ydr52Hykq"
      }
    }
  ]
}